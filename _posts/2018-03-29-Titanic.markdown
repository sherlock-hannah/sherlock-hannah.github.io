---
layout: post
title:  "Titanic"
date:   2018-03-29 18:43:31 +0800
categories: jekyll update
---
## Decription
predict which passengers survived from the titanic sinking
## Data

| variable     | description                    |  
| :------------| :-------------                 |
| PassengerId  | int64                          |
| survived     | int64 Survival 0 = No, 1 = Yes |
| Pclass       | 1(upper),2(middle),3(lower)    |
| Name         | varchar                        |
| Sex          | varchar male or female         |
| Age          | float64                        |
| SibSp        | int64 sibship numbers          |
| Parch        | Parent Child                   |
| Ticket       | varchar                        |
| Fare         | float64 price of Ticket        |
| Cabin        | varchar                        |
| Embarked     | embarked	Portof Embarkation    |

## Goal
For each PassengerId, predict a 0 or 1 value for the Survived variable.

binary classifier problem.
## Metric
the percentage of passengers you correctly predict

TRUE positive/sum of test id
## Analysis

![pclassandage](/pictures/pclassandage.png)

![agedistribution](../pictures/agedistribution.png)


![notalone](../pictures/notalone.png)

![survivedandfeatures](../pictures/survivedandfeature.png)

![survivedandsib](../pictures/survivedandsib.png)

![PearsonCorrelationHeatmap](../pictures/PearsonCorrelationHeatmap.png)
some correlation plots of the features to see how related one feature is to the next.

![pairplot](../pictures/pairplot.png)

## feature engnieering
[kaggle](https://www.kaggle.com/mitakayama/titanic-python-solutions)


## Model_selection
1. linear regression

```
from sklearn.linear_model import LinearRegression
from sklearn.cross_validation import KFold  

predictors = ['Pclass','Sex','Age','SibSp','Parch','Fare']  

alg = LinearRegression()  

kf = KFold(titanic.shape[0],n_folds=3,random_state=1)  

predictions = []  

for train, test in kf:  
    train_predictors = (titanic[predictors].iloc[train,:])
    train_target = titanic['Survived'].iloc[train]  
    alg.fit(train_predictors,train_target)    
    test_prediction = alg.predict(titanic[predictors].iloc[test,:])  
    predictions.append(test_prediction)
```
cross_validation :first divide dataset into k subset,set k-1 subset as trainset,the least as testset,perform k train and test ,return the mean of result.


2. logistic regression

```
from sklearn.linear_model import LogisticRegression
from sklearn import cross_validation  

LR = LogisticRegression(random_state=1)  
scores = cross_validation.cross_val_score(LR, titanic[predictors],titanic['Survived'],cv=3)  
print scores.mean()  
plot_learning_curve(LR, u'learning_rate', titanic[predictors], titanic['Survived'])

```

3. RandomForest
```
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(criterion='gini',
                             n_estimators=700,
                             min_samples_split=10,
                             min_samples_leaf=1,
                             max_features='auto',
                             oob_score=True,
                             random_state=1,
                             n_jobs=-1)
rf.fit(train.iloc[:, 1:], train.iloc[:, 0])
print("%.4f" % rf.oob_score_)


pd.concat((pd.DataFrame(train.iloc[:, 1:].columns, columns = ['variable']),
           pd.DataFrame(rf.feature_importances_, columns = ['importance'])),
          axis = 1).sort_values(by='importance', ascending = False)[:20]
```

4. decision tree

```
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(X_train, y_train)
```






[online_test](https://classroom.udacity.com/nanodegrees/nd009-cn-preview/parts/d88d49be-6d08-43b2-90da-29de3603d321/modules/9a2f317e-48d2-4f9f-894b-4ce362b18720/lessons/a31de5d2-25c3-4fdb-b4f4-5a15770ff888/concepts/c61735ea-8a4f-4e98-b4a9-a2a855e824f5)






## submit
```
predictions = rf.predict(test)

test = pd.read_csv("../input/test.csv")

submission = pd.DataFrame({ 'PassengerId': test['PassengerId'], 'Survived': predictions})
submission.to_csv('submit.csv', index=False)
```






## Problems
1.when I use linux ,it couldn't show my drawings.so at first I should put `%matlotlib inline`
2.deprecation warning when using sklearn 0.19 , the solution is using `from sklearn.model_selection import KFold` instead of `from sklearn.cross_validation import KFold`
